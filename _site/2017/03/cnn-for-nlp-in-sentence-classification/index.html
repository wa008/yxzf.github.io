<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>CNN在NLP的应用--文本分类 • YXZF's  Blog</title>
    <meta name="description" content="刚接触深度学习时知道CNN一般用于计算机视觉，RNN等一般用于自然语言相关。CNN目前在CV领域独领风骚，自然就有想法将CNN迁移到NLP中。但是NLP与CV不太一样，NLP有语言内存的结构，所以最开始CNN在NLP领域的应用在文本分类。相比于具体的句法分析、语义分析的应用，文本分类不需要精准分析。本文主要介绍最近学习到几个算法，并用mxnet进行了实现，如有错误请大家指出。

">
    <meta name="keywords" content="CNN, NLP">
    
    
    	<!-- Twitter Cards -->
	<meta name="twitter:title" content="CNN在NLP的应用--文本分类">
	<meta name="twitter:description" content="刚接触深度学习时知道CNN一般用于计算机视觉，RNN等一般用于自然语言相关。CNN目前在CV领域独领风骚，自然就有想法将CNN迁移到NLP中。但是NLP与CV不太一样，NLP有语言内存的结构，所以最开始CNN在NLP领域的应用在文本分类。相比于具体的句法分析、语义分析的应用，文本分类不需要精准分析。本文主要介绍最近学习到几个算法，并用mxnet进行了实现，如有错误请大家指出。

">
	
	
	
	<meta name="twitter:card" content="summary">
	<meta name="twitter:image" content="/images/logo.jpg">
	
	<!-- Open Graph -->
	<meta property="og:locale" content="">
	<meta property="og:type" content="article">
	<meta property="og:title" content="CNN在NLP的应用--文本分类">
	<meta property="og:description" content="刚接触深度学习时知道CNN一般用于计算机视觉，RNN等一般用于自然语言相关。CNN目前在CV领域独领风骚，自然就有想法将CNN迁移到NLP中。但是NLP与CV不太一样，NLP有语言内存的结构，所以最开始CNN在NLP领域的应用在文本分类。相比于具体的句法分析、语义分析的应用，文本分类不需要精准分析。本文主要介绍最近学习到几个算法，并用mxnet进行了实现，如有错误请大家指出。

">
	<meta property="og:url" content="/2017/03/cnn-for-nlp-in-sentence-classification/">
	<meta property="og:site_name" content="YXZF's  Blog">
    

    <link rel="canonical" href="/2017/03/cnn-for-nlp-in-sentence-classification/">

    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="YXZF's  Blog Atom Feed">
    <link href="/sitemap.xml" type="application/xml" rel="sitemap" title="Sitemap">

    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="cleartype" content="on">

    <style>
    .sliding-menu-content {
      top: 0;
      right: 0;
      text-align: center;
      visibility: hidden;
      height: 100%;
      width: 100%;
      -webkit-transform: translateX(100%);
      -moz-transform: translateX(100%);
      -ms-transform: translateX(100%);
      -o-transform: translateX(100%);
      transform: translateX(100%);
    }
    </style>

    <link rel="stylesheet" href="/css/main.css">
    <!-- HTML5 Shiv and Media Query Support for IE -->
    <!--[if lt IE 9]>
      <script src="/js/vendor/html5shiv.min.js"></script>
      <script src="/js/vendor/respond.min.js"></script>
    <![endif]-->

  </head>

  <body>
    <header id="masthead">
  <div class="inner-wrap">
    <a href="/" class="site-title">YXZF's  Blog</a>
    <nav role="navigation" class="menu top-menu">
        <ul class="menu-item">
	<li class="home"><a href="/">YXZF's  Blog</a></li>
	
    
        
    
    <li><a href="/" >主页</a></li>
  
    
        
    
    <li><a href="/datamining/" >数据挖掘</a></li>
  
    
        
    
    <li><a href="/deeplearning/" >深度学习</a></li>
  
    
        
    
    <li><a href="/development/" >开发</a></li>
  
    
        
    
    <li><a href="/math/" >数学</a></li>
  
    
        
    
    <li><a href="/about/" >关于</a></li>
  
</ul>
    </nav>
  </div><!-- /.inner-wrap -->
</header><!-- /.masthead -->
    <nav role="navigation" class="js-menu sliding-menu-content">
    <ul class="menu-item">
        <li>
      
        
      
            
            <a href="/" class="title">主页</a>
            
        </li><li>
      
        
      
            
            <a href="/datamining/" class="title">数据挖掘</a>
            
        </li><li>
      
        
      
            
            <a href="/deeplearning/" class="title">深度学习</a>
            
        </li><li>
      
        
      
            
            <a href="/development/" class="title">开发</a>
            
        </li><li>
      
        
      
            
            <a href="/math/" class="title">数学</a>
            
        </li><li>
      
        
      
            
            <a href="/about/" class="title">关于</a>
            
        </li>
    </ul>
</nav>
<button type="button" class="js-menu-trigger sliding-menu-button menulines-button x2" role="button" aria-label="Toggle Navigation">
    <span class="menulines"></span>
</button>

<div class="js-menu-screen menu-screen"></div>


    <div id="page-wrapper">
      <!--[if lt IE 9]><div class="upgrade notice-danger"><strong>Your browser is quite old!</strong> Why not <a href="http://whatbrowser.org/">upgrade to a newer one</a> to better enjoy this site?</div><![endif]-->

      <div id="main" role="main">
    <article class="wrap" itemscope itemtype="http://schema.org/Article">
        
        <div class="page-title">
            <h1>CNN在NLP的应用--文本分类</h1>
        </div>
        <div class="inner-wrap">
            
            <div id="content" class="page-content" itemprop="articleBody">
                <p>刚接触深度学习时知道CNN一般用于计算机视觉，RNN等一般用于自然语言相关。CNN目前在CV领域独领风骚，自然就有想法将CNN迁移到NLP中。但是NLP与CV不太一样，NLP有语言内存的结构，所以最开始CNN在NLP领域的应用在文本分类。相比于具体的句法分析、语义分析的应用，文本分类不需要精准分析。本文主要介绍最近学习到几个算法，并用mxnet进行了实现，如有错误请大家指出。</p>

<h4 id="convolutional-neural-networks-for-sentence-classification">1 Convolutional Neural Networks for Sentence Classification</h4>
<p>##### 1.1 原理<br />
<img src="/images/deeplearning/cnn_nlp/model1.png" alt="" /><br />
CNN的输入是矩阵形式，因此首先是构造矩阵。句子有词构成，DL中一般使用词向量，再对句子的长度设置一个固定值（可以是最大长度），那么就可以构造一个矩阵，这样就可以应用CNN了。这篇论文就是这样的思想，如上图所示。</p>

<h6 id="section">输入层</h6>
<p>句子长度为$n$，词向量的维度为$k$，那么矩阵就是$n*k$。具体的，词向量可以是静态的或者动态的。静态指词向量提取利用word2vec等得到，动态指词向量是在模型整体训练过程中得到。</p>

<h6 id="section-1">卷积层</h6>
<p>一个卷积层的kernel大小为$h<em>k$，$k$为输入层词向量的维度，那么$h$为窗口内词的数目。这样可以看做为N-Gram的变种。如此一个卷积操作可以得到一个$(n-h+1)</em>1$的feature map。多个卷积操作就可以得到多个这样的feature map</p>

<h6 id="section-2">池化层</h6>
<p>这里面的池化层比较简单，就是一个Max-over-time Pooling，从前面的1维的feature map中取最大值。<a href="http://blog.csdn.net/malefactor/article/details/51078135#0-tsina-1-38411-397232819ff9a47a7b7e80a40613cfe1">这篇文章</a>中给出了NLP中CNN的常用Pooling方法。最终将会得到1维的size=m的向量(m=卷积的数目)</p>

<h6 id="section-3">全连接+输出层</h6>
<p>模型的输出层就是全连接+Softmax。可以加上通用的Dropout和正则的方法来优化</p>

<h5 id="section-4">1.2 实现</h5>
<p><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/">这篇文章</a>用TensorFlow实现了这个模型，<a href="https://github.com/dennybritz/cnn-text-classification-tf">代码</a>。我参考这个代码用mxnet实现了，<a href="https://github.com/yxzf/cnn-text-classification-mx">代码</a></p>

<h4 id="character-level-convolutional-networks-for-text-classification">2 Character-level Convolutional Networks for Text Classification</h4>
<p>##### 2.1 原理<br />
图像的基本都要是像素单元，那么在语言中基本的单元应该是字符。CNN在图像中有效就是从原始特征不断向上提取高阶特征，那么在NLP中可以从字符构造矩阵，再应用CNN来做。这篇论文就是这个思路。<br />
<img src="/images/deeplearning/cnn_nlp/model2.png" alt="" /><br />
###### 输入层<br />
一个句子构造一个矩阵，句子由字符构成。设定一个句子的字符数目$n$(论文中$n=1014$)。每个字符是一个字符向量，这个字符向量可以是one-hot向量，也可以是一个char embeding. 设字符向量为$k$，那么矩阵为$n*k$。<br />
###### 卷积层<br />
这里的卷积层就是套用在图像领域的， 论文中给出具体的设置<br />
<img src="/images/deeplearning/cnn_nlp/model2_conv.png" alt="" /><br />
###### 全连接+输出层<br />
全连接层的具体设置如下<br />
![/images/deeplearning/cnn_nlp/model2_fc.png]</p>

<h5 id="section-5">2.2 实现</h5>
<p><a href="https://github.com/scharmchi/char-level-cnn-tf">代码</a>给出了TensorFlow的实现，我用mxnet实现的<a href="https://github.com/yxzf/char-level-cnn-mx">代码</a></p>

<h4 id="character-aware-neural-language-models">3 Character-Aware Neural Language Models</h4>
<p>##### 3.1 原理<br />
这篇文章提出一种CNN+RNN结合的模型。CNN部分，每个单词由character组成，如果对character构造embeding向量，则可以对单词构造矩阵作为CNN的输入。CNN的输出为词向量，作为RNN的输入，RNN的输出则是以整个词为单位。<br />
<img src="/images/deeplearning/cnn_nlp/char-cnn-rnn.png" alt="" /><br />
###### 3.1.1 CNN层<br />
<strong>输入层</strong>: 一个句子(sentence)是一个输入样本，句子由词(word)构成，词由字符(character)组成。每个字符学习一个embeding字符向量，设字符向量长度为$k$，那么一个word(长度为$w$)就可以构造成一个矩阵C($k*w$)</p>

<p><strong>卷积层</strong>:<br />
对这个矩阵C使用多个卷积层，每个卷积层的kernel大小为($k<em>n$)。卷积层可以看作是character的n-gram，那么每个卷积操作后得到的矩阵为($1</em>(w-n+1)$)</p>

<p><strong>池化层</strong>:<br />
池化层仍是max-pooling，挑选出($w-n+1$)长度向量中的最大值，将所有池化层的结果拼接就可以得到定长的向量$p$，$p$的长度为所有卷积层的数目</p>

<p><strong>Highway层</strong>:<br />
<a href="https://arxiv.org/pdf/1505.00387.pdf">Highway层</a>是最近刚提出的一种结构，借鉴LSTM的gate概念。$x$为该层的输入，那么首先计算一个非线性转换$T(x)$，$T(x)\in [0, 1]$($T$一般为sigmod)。除了$T(x)$，还有另外一个非线性转换$H(x)$，最终的输出为$y = T(x) * H(x) + (1 - T(x)) * x$。从公式来看，$T(x)$充当了gate，如果$T(x)=1$，那么输出同传统的非线性层一样，输出是$H(x)$，如果$T(x)=0$，则直接输出输入$x$。作者认为Highway层的引入避免了梯度的快速消失，这种特性可以构建更深的网络。</p>

<p><strong>输出层</strong>:<br />
每个单词将得到一个词向量，与一般的词向量获取不同，这里的词向量是DNN在character embeding上得到的。</p>

<h6 id="rnn">3.1.2 RNN层</h6>
<p><strong>输入层</strong>:<br />
将一个句子的每个CNN输出作为词向量，整个句子就是RNN的输入层</p>

<p><strong>隐藏层</strong>:<br />
一般使用LSTM，也可以是GRU</p>

<p><strong>输出层</strong>:<br />
输出层以word为单位，而不是character. </p>

<h5 id="section-6">3.2实现</h5>
<p><a href="https://github.com/carpedm20/lstm-char-cnn-tensorflow">代码</a>给出了TensorFlow的实现，我的MXNet实现见<a href="https://github.com/yxzf/lstm-char-cnn-mx">代码</a></p>

<h4 id="section-7">参考资料</h4>
<ol>
  <li>https://github.com/Lasagne/Lasagne/blob/highway_example/examples/Highway%20Networks.ipynb</li>
  <li>http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html</li>
  <li>http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/</li>
  <li>http://www.wtoutiao.com/p/H08qKy.html</li>
  <li>http://karpathy.github.io/2015/05/21/rnn-effectiveness/</li>
  <li>https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf</li>
</ol>

                <hr />
                <footer class="page-footer">
                    


<div class="author-image">
	<img src="/images/logo.jpg" alt="沈成光">
</div><!-- ./author-image -->
<div class="author-content">
	<h3 class="author-name" >Written by <span itemprop="author">沈成光</span></h3>
	<p class="author-bio"></p>
</div><!-- ./author-content -->
                    <div class="inline-btn">
    <a class="btn-social twitter" href="https://twitter.com/intent/tweet?text=CNN在NLP的应用--文本分类&amp;url=/2017/03/cnn-for-nlp-in-sentence-classification/&amp;via=" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i> Share on Twitter</a> 
<!-- <a class="btn-social twitter" href="http://service.weibo.com/share/share.php?title=CNN在NLP的应用--文本分类&url=/2017/03/cnn-for-nlp-in-sentence-classification/&changweibo=yes&ralateUid=1278841597" target='_newtab' type="submit" class="submit">分享到微博</a> -->
    <a class="btn-social facebook" href="https://www.facebook.com/sharer/sharer.php?u=/2017/03/cnn-for-nlp-in-sentence-classification/" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i> Share on Facebook</a>
    <a class="btn-social google-plus"  href="https://plus.google.com/share?url=/2017/03/cnn-for-nlp-in-sentence-classification/" target="_blank"><i class="fa fa-google-plus" aria-hidden="true"></i> Share on Google+</a>
</div><!-- /.share-this -->

                    <div class="page-meta">
	<p>Updated <time datetime="2017-03-12T00:00:00Z" itemprop="datePublished">March 12, 2017</time></p>
</div><!-- /.page-meta -->
                </footer><!-- /.footer -->
                <!-- JiaThis Button BEGIN -->
<div class="jiathis_style_32x32">
    <a class="jiathis_button_weixin"></a>
    <a class="jiathis_button_tsina"></a>
    <a class="jiathis_button_tqq"></a>
    <a class="jiathis_button_qzone"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
    <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

                <aside>
                    <section class="comment">
<!-- baidu JIA -->
<div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a title="分享到QQ空间" href="#" class="bds_qzone" data-cmd="qzone"></a><a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a><a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a><a title="分享到人人网" href="#" class="bds_renren" data-cmd="renren"></a><a title="分享到微信" href="#" class="bds_weixin" data-cmd="weixin"></a></div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>
<!-- end of baidu JIA -->

<!-- 多说评论框 start -->
    <div class="ds-thread" data-thread-key="/2017/03/cnn-for-nlp-in-sentence-classification/" data-title="CNN在NLP的应用--文本分类" data-url="/2017/03/cnn-for-nlp-in-sentence-classification/"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"yxzf"};
    (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] 
         || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
    </script>
<!-- 多说公共JS代码 end -->


</section>

                </aside>
            </div><!-- /.content -->
        </div><!-- /.inner-wrap -->
        <div class="ads"><script src="//about.me/chengguang.shen"></script>
</div>
    </article><!-- ./wrap -->
</div><!-- /#main -->
<script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-57330114-1', 'auto');
      ga('send', 'pageview');
</script>

<script>
    var _hmt = _hmt || [];
    (function() {
           var hm = document.createElement("script");
             hm.src = "//hm.baidu.com/hm.js?138fcb8c5448d0003de5abef31cdd0b9";
               var s = document.getElementsByTagName("script")[0]; 
                 s.parentNode.insertBefore(hm, s);
                 })();
</script>


<script type="text/javascript"
     src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
     MathJax.Hub.Config({
       extensions: ["tex2jax.js","TeX/noErrors.js","TeX/AMSsymbols.js"],
       jax: ["input/TeX","output/HTML-CSS"],
       tex2jax: {
         inlineMath: [['$','$'],["\\(","\\)"]],
         displayMath: [['\\[','\\]'], ['$$','$$']],
         balanceBraces: true
       },
       TeX: {equationNumbers: {autoNumber: ["AMS"], useLabelIds: true}},
       "HTML-CSS": {availableFonts:["TeX"]},
       });
      MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
</script>


      <footer role="contentinfo" id="site-footer">
	<nav role="navigation" class="menu bottom-menu">
		<ul class="menu-item">
		
      
        
      
			<li><a href="" ></a></li>
		
		</ul>
	</nav><!-- /.bottom-menu -->
	<p class="copyright">&#169; 2017 <a href="">YXZF's  Blog</a> powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> + <a href="http://mmistakes.github.io/skinny-bones-jekyll/" rel="nofollow">Skinny Bones</a>.</p>
</footer>
    </div>

    <script src="/js/vendor/jquery-1.9.1.min.js"></script>
    <script src="/js/main.js"></script>
    
    

  </body>

</html>
